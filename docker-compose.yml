version: '3.8'

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    depends_on:
      - backend-java
    networks:
      - loyalty-network

  backend-java:
    build:
      context: ./backend-java
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - SPRING_DATA_MONGODB_URI=mongodb://mongodb:27017/loyalty
      - SPRING_DATA_MONGODB_DATABASE=loyalty
      - CORS_ALLOWED_ORIGINS=http://localhost:3000
      - JWT_SECRET=c9c1b2f3e4a5d6b7c8a9e0f1d2c3b4a5e6f7a8b9c0d1e2f3a4b5c6d7e8f9a0b1c2d3e4f5a6b7c8d9e0f1
      - BLOCKCHAIN_API_URL=http://localhost:8081
    depends_on:
      - mongodb
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 3
    networks:
      - loyalty-network

  mongodb:
    image: mongo:latest
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    networks:
      - loyalty-network

  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - loyalty-network
    environment:
      - OLLAMA_MODELS=/root/.ollama/models
      - OLLAMA_HOST=0.0.0.0
      # Tối ưu cao cho Mac M1
      - OLLAMA_TIMEOUT=90
      - OLLAMA_CONTEXT_LENGTH=1024
      - OLLAMA_NUM_THREAD=8
      - OLLAMA_NUM_GPU=1  # Bật GPU cho M1
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_KEEP_ALIVE=10m
      - OLLAMA_FLASH_ATTENTION=1
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4'
        reservations:
          memory: 4G
          cpus: '2'
    command: ["serve"]
    # healthcheck:
    #   test: ["CMD-SHELL", "ollama --version > /dev/null 2>&1"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 3
    #   start_period: 20s

  ollama-pull:
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - loyalty-network
    environment:
      - OLLAMA_HOST=http://ollama:11434
    command: ["pull", "phi3"]
    depends_on:
      - ollama

  llm-service:
    build:
      context: ./llm-guard-service
      dockerfile: Dockerfile
    ports:
      - "8082:8000"
    environment:
      - OLLAMA_API_URL=http://ollama:11434
      - OLLAMA_MODEL=meta-llama-3-8b-instruct
      - OLLAMA_TIMEOUT=180
      - HF_HOME=/root/.cache/huggingface
    volumes:
      - llm_cache:/root/.cache/huggingface
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 3
    #   start_period: 10s
    depends_on:
      - ollama
      - ollama-pull
    # condition: service_completed_successfully
    networks:
      - loyalty-network

networks:
  loyalty-network:
    driver: bridge

volumes:
  mongodb_data:
  ollama_data:
  llm_cache:
